{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic machine learning workflow\n",
    "\n",
    "Refer back to **4-2_Machine-Learning-Review.pdf** to review your key terms. Below is a simplified workflow:\n",
    "\n",
    "1. Do you want to predict something? \n",
    "    - Yes = supervised learning (y ~ x)\n",
    "    - No = unsupervised learning (~ x)\n",
    "2. If supervised:\n",
    "    - Syntax looks like this: **y ~ x** ([use x to predict y](https://stats.stackexchange.com/questions/207425/why-do-we-say-the-outcome-variable-is-regressed-on-the-predictors))\n",
    "    - **y** is the thing we want to predict! (dependent/target/outcome variable)\n",
    "    - **x** is the thing(s) we use to do the predicting (independent/predictor/input variable)\n",
    "3. If supervised:\n",
    "    - perform **regression** if the **y** variable is continuous\n",
    "    - perform **classification** if the **y** variable is discrete/categorical\n",
    "4. If unsupervised: \n",
    "    - Syntax looks like this: **~ x**\n",
    "    - We only have **x** variables, and we want to see how they sort on their own accord without trying to predict anything.\n",
    "5. Handle missing data\n",
    "    - Missing data should be handled somehow. [Listwise deletion](https://en.wikipedia.org/wiki/Listwise_deletion) is common but not preferred because of the amount of information that is lost. [Mean imputation](https://en.wikipedia.org/wiki/Imputation_(statistics)#Mean_substitution) is also used but is sensitive to outliers. [Median imputation](https://stats.stackexchange.com/questions/143700/which-is-better-replacement-by-mean-and-replacement-by-median) is often reliable and interpretable. [Generalized low rank models](https://web.stanford.edu/~boyd/papers/pdf/glrm.pdf) are preferred! \n",
    "6. Convert categorical variables to indicators\n",
    "    - Use [one-hot encoding](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f) to your advantage! Most supervised algorithms handle factor/categorical data poorly (decision trees being a main exception). \n",
    "7. Split the data\n",
    "    - [Split the original dataset](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets) so that (arbitrarily) 70% is assigned to the **training set** and the remaining 30% to the **test set**. \n",
    "        - Use [random sampling]() if you are splitting continuous data. \n",
    "        - Use [stratified](https://en.wikipedia.org/wiki/Stratified_sampling) [sampling](https://www.investopedia.com/ask/answers/032615/what-are-some-examples-stratified-random-sampling.asp#:~:text=Stratified%20random%20sampling%20divides%20a,of%20the%20groups%20or%20strata.&text=Stratified%20random%20sampling%20is%20a%20method%20of%20sampling%2C%20which%20is,a%20sample%20size%20for%20study.) if you are splitting categorical data. \n",
    "    - [Data splitting](https://www.mff.cuni.cz/veda/konference/wds/proc/pdf10/WDS10_105_i1_Reitermanova.pdf) is a fundamental preprocessing step! \n",
    "    - [Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) is even better because it repeats this splitting _k_ number of times.\n",
    "8. Fit the model to the training set and evaluate its performance. \n",
    "    - Fit the data to the training set so it can \"learn\" the relationships between the **x and y** variables. \n",
    "    - Then use a [performance](https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce) [metric](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers) to see how well the model fit the data. \n",
    "    - What is a [loss](https://en.wikipedia.org/wiki/Loss_functions_for_classification) [function](https://medium.com/@phuctrt/loss-functions-why-what-where-or-when-189815343d3f)?\n",
    "    - The model is **underfit** if the model performs poorly on the training dataset. \n",
    "9. Fit the data to the test set and evaluate its performance\n",
    "    - See how well the model performs on the test set; hopefully we see roughly similar performances for the training and test sets. \n",
    "    - The model is **overfit** if the model performs poorly on the training dataset but poorly on the test dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The value of understanding simple linear regression\n",
    "\n",
    "Doing a simple [OLS](https://en.wikipedia.org/wiki/Ordinary_least_squares) regression step-by-step provides a way to understand the supervised machine learning process. \n",
    "\n",
    "> NOTE: Remember to [learn the assumptions of linear or logistic regression (or any other statistical test)](https://www.lexjansen.com/wuss/2018/130_Final_Paper_PDF.pdf) before using it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate some data\n",
    "\n",
    "First, let's generate toy predictor x and response y variables and compute their means. This will be our \"training set\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x    y\n",
       "0  1.0  4.0\n",
       "1  1.5  3.0\n",
       "2  4.0  8.2\n",
       "3  7.0  9.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate toy predictor (x) and response (y) variables\n",
    "x = np.array([1, 1.5, 4, 7])\n",
    "y = np.array([4, 3, 8.2, 9])\n",
    "\n",
    "# Convert to data frame\n",
    "df = pd.DataFrame({\"x\": x,\n",
    "                   \"y\": y})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate means of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of x is: 3.38\n",
      "mean of y is: 6.05\n"
     ]
    }
   ],
   "source": [
    "mean_x = round(sum(df.x) / len(df.x), 2)\n",
    "mean_y = round(sum(df.y) / len(df.y), 2)\n",
    "print(\"mean of x is:\", mean_x)\n",
    "print(\"mean of y is:\", mean_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.scatter(x = \"x\", y = \"y\", \n",
    "               figsize = (6,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the error for each observation\n",
    "\n",
    "Numpy allows us to perform \"vectorized\" operations, such as subtracting the mean of x from each x value or the mean of y from each y value. That is, we can do math on arrays of numbers simultaneously: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point errors for x is: [-2.38 -1.88  0.62  3.62]\n",
      "Point errors for y is: [-2.05 -3.05  2.15  2.95]\n"
     ]
    }
   ],
   "source": [
    "print(\"Point errors for x is:\", x - mean_x)\n",
    "print(\"Point errors for y is:\", y - mean_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate the beta coefficients\n",
    "\n",
    "Error is important bcause it helps us calculate the [beta coefficeints](https://en.wikipedia.org/wiki/Standardized_coefficient) to plot the slope and intercept of the best fit line, which minimizes the sum of the squared errors (the vertical distances between each point and the line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope (B1) is equal to 0.99724\n",
      "intercept (B0) is equal to 2.67933\n"
     ]
    }
   ],
   "source": [
    "## Estimate the B1 coefficient (slope)\n",
    "B1 = sum((x - mean_x) * (y-mean_y)) / sum((x - mean_x) **2)\n",
    "print(\"slope (B1) is equal to\", round(B1, 5))\n",
    "\n",
    "## Estimate B0 coefficient (intercept)\n",
    "B0 = mean_y - (B1 * mean_x)\n",
    "print(\"intercept (B0) is equal to\", round(B0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plot the best fit line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x = \"x\", y = \"y\", \n",
    "            data = df, \n",
    "            ci = None); \n",
    "            # ci = 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Generate predicted values\n",
    "\n",
    "Now that we have calculated the best fit line, we can generate predicted values (our \"test set\") and assess the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual y values are: [4.  3.  8.2 9. ]\n",
      "\n",
      "The predicted y values are: [3.67656694 4.17518733 6.66828929 9.66001164]\n"
     ]
    }
   ],
   "source": [
    "# Generate predicted y values by plugging our x values into the equation\n",
    "y_hat = B0 + B1 * x\n",
    "print(\"The actual y values are:\", y)\n",
    "print()\n",
    "print(\"The predicted y values are:\", y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Evaluate performance\n",
    "\n",
    "Our performance metric will be [root mean square error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation), or the standard deviation of the residuals (aka prediction errors). Error is measured as the vertical distance from a data point to the best fit line. \n",
    "\n",
    "However, we have to do some calculations first before we get to RMSE! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32343306 -1.17518733  1.53171071 -0.66001164]\n"
     ]
    }
   ],
   "source": [
    "# First, calculate the error for each observation by subracting the predicted value from it:\n",
    "Y_error = y - y_hat\n",
    "print(Y_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10460895 1.38106525 2.34613771 0.43561536]\n"
     ]
    }
   ],
   "source": [
    "## Second, calculate the square of each of these errors:\n",
    "Y_error_sq = Y_error ** 2\n",
    "print(Y_error_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.267427273047831\n"
     ]
    }
   ],
   "source": [
    "## Third, sum these values\n",
    "sum_squared_error = sum(Y_error_sq)\n",
    "print(sum_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03289\n"
     ]
    }
   ],
   "source": [
    "## Fourth, calculate the RMSE - take the square root of the summed squared error divided by the length of Y:\n",
    "RMSE = math.sqrt(sum_squared_error / len(y))\n",
    "print(round(RMSE, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. How did we do? \n",
    "\n",
    "Compare the slope and intercept from `stats.linregress` to our estimations by hand. Are they the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=0.9972451790633609, intercept=2.684297520661157, rvalue=0.9170329283008835, pvalue=0.08296707169911656, stderr=0.30666886418034517)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_mod = scipy.stats.linregress(x, y)\n",
    "lin_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate RMSE from the `sklearn.metrics.mean_squared_error` function to compare to our estimations by hand. How did we do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neat! Same thing! \n",
    "math.sqrt(sklearn.metrics.mean_squared_error(y, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What does each point represent in the graphs? \n",
    "2. What does the best fit line represent? \n",
    "3. What is the name of the distance between each point and the line? \n",
    "4. What does RMSE tell us? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "[Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) provides a useful way to classify text. Don't be fooled, however - even though it has _regression_ in its name know that it can perform both both regression and classification. That is to say that the **y** variable can be either continuous or categorical. First, create some toy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = pd.DataFrame({'Study_Hours' : [2.0, 6.9, 1.6, 9.8, 1.1, 5.8, 3.4, 8.5, 6.7, 1.6, 8.6, 3.4, 9.4, 5.6, 12.0, 3.2, 3.5, 6, 9.7, 6.5],\n",
    "                      'Grade' : [60.0, 83.6, 35.4, 79.2, 42.4, 98.2, 67.6, 84.0, 93.8, 64.4, 100.0, 61.6, 100.0, 69.4, 98.4, 41.8, 72.0, 59.0, 90.8, 100.0],\n",
    "                      'Pass' : [1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1]})\n",
    "study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data\n",
    "\n",
    "Linear regression, in its simple form, tries to model the relationship between two continous variables as a straight line. It interprets one variable as the input (x), and the other as the output y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = \"Study_Hours\", y = \"Grade\", \n",
    "            data = study, color = \"k\",\n",
    "            line_kws={'color':'purple'});\n",
    "print(stats.linregress(x = study.Study_Hours, y = study.Grade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuiting the Logistic Regression Model\n",
    "\n",
    "But what happens if your **y** variable is categorical and not continuous? Suppose we don't care about the `Grade` score, but we just care if you pass the course or not?\n",
    "\n",
    "0 = no pass  \n",
    "1 = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we fit a line to that? That's where the [logistic function](https://en.wikipedia.org/wiki/Logistic_function) can be handy. The general logistic function is:\n",
    "\n",
    "$ f(x) = \\frac{1}{1 + e^{-x}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `LogisticRegression` function\n",
    "\n",
    "Let's go back to `sklearn` and save our logistic model in a variable named `lr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = \"liblinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll `reshape` our arrays since scikit-learn prefers them in a specified format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(study['Study_Hours']).reshape(-1,1)\n",
    "y = np.array(study['Pass']).reshape(len(study['Pass']),)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `fit` function again on our `x` and `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = study.Study_Hours, y = study.Pass, \n",
    "            logistic = True, \n",
    "            color = \"k\",\n",
    "            line_kws={'color':'red'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and test split\n",
    "\n",
    "Well, let's see how the logistic regression performs on training and test set data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x and y variables for training and test sets. Split the data! \n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    # Which dataset? \n",
    "    study, \n",
    "    \n",
    "    # What is the outcome variable?\n",
    "    study.Pass, \n",
    "    \n",
    "    # How much data should be assigned to the test set? \n",
    "    # 1 minus this number will be automatically assigned to the training set\n",
    "    test_size = 0.30, \n",
    "    \n",
    "    # Ensure we get the same train/test split each time\n",
    "    random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default settings except for the solver!\n",
    "# https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions\n",
    "logistreg = LogisticRegression(solver = \"liblinear\")\n",
    "logistreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "logistreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted y values based on the x test set data\n",
    "predictions = logistreg.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification accuracy on the training set\n",
    "# Nice! \n",
    "logistreg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification accuracy on the test set\n",
    "score = logistreg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix: https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fancy it up! Use plt.savefig() to export\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot = True, fmt = \".0f\", \n",
    "            cbar = False, linewidths = 2, \n",
    "            square = True, cmap = 'YlGnBu', annot_kws={\"size\": 20})\n",
    "plt.ylabel('Actual y label')\n",
    "plt.xlabel('Predicted y label')\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other algorithms\n",
    "\n",
    "This is the gist! Download the [Machine Learning in Python](https://github.com/dlab-berkeley/python-machine-learning) materials to see how other algorithms work. \n",
    "\n",
    "    - What's up with tree-based methods? \n",
    "    - What is a random forest? \n",
    "    - How do their accuracy scores compare to our logistic regression? \n",
    "    - What is AUC and is it better than simple accuracy?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
